from typing import Iterable, Optional


class Prepare:
    """
    Prepares cleaned and aligned datasets for training by applying splits, shaping,
    and converting them into optimized binary formats compatible with major ML frameworks.

    The `Prepare` module serves as the final transformation stage before training.
    It coordinates multi-source alignment (e.g., features, targets, metadata), applies
    dataset splits, and writes training-ready files in efficient I/O formats such as
    `.npy`, `.npz`, `.tfrecord`, and others.

    It is designed to be flexible across data types—including tabular, time series, 
    text, image, audio, and reinforcement learning inputs—and can integrate outputs
    from the `Extract`, `Transform`, and `Clean` modules. For time-dependent or 
    episodic data (e.g., RL or forecasting), it supports rolling window generation
    and grouped sampling.

    Key Responsibilities:
    ---------------------
    - Register and align multiple data sources using shared keys or indices.
    - Apply train/val/test splits with optional stratification or reproducible seeding.
    - Convert data into binary formats optimized for TensorFlow, PyTorch, and XGBoost.
    - Handle exclusion lists (from `Clean`) to remove invalid samples pre-conversion.
    - Support windowed or episodic dataset shaping for RL and time series tasks.
    - Log output metadata for reproducibility (e.g., sample counts, shape, exclusions, splits).

    Methods:
    --------
    register_source(name: str, data: Iterable)
        Register a named data source (e.g., "features", "targets", "metadata").

    load_exclusion_keys(tag: str, path: Optional[str] = None)
        Load a list of keys to exclude (generated by the `Clean` module).

    set_split(train: float, val: float = 0.0, test: float = 0.0, seed: Optional[int] = None)
        Define split ratios and optional random seed for reproducibility.

    apply_rolling_windows(window_size: int, step: int = 1)
        Apply sliding window reshaping to time series or RL-style input data.

    convert(output_format: str = "npy", output_dir: str = "./data/processed/")
        Convert registered sources into aligned, formatted training datasets.

    prepare_rl_dataset(state_source, action_source, reward_source, next_state_source, done_source, ...)
        Align and format structured RL logs into (state, action, reward, next_state, done) transitions.

    save_metadata(path: str = "./data/processed/metadata.json")
        Store conversion configuration and metadata for reproducibility.

    Example:
    --------
    >>> prepare = Prepare()
    >>> prepare.register_source("features", extractor.load_csv("features.csv", batch_size=1000))
    >>> prepare.register_source("targets", extractor.load_csv("targets.csv", batch_size=1000))
    >>> prepare.load_exclusion_keys("cleaned_v1")
    >>> prepare.set_split(train=0.7, val=0.2, test=0.1, seed=42)
    >>> prepare.apply_rolling_windows(window_size=30)
    >>> prepare.convert(output_format="npy", output_dir="./data/prepared/")

    Notes:
    ------
    - All registered sources must align on sample keys or row order.
    - Data is written to disk in a format optimized for your selected ML framework.
    - For RL workflows, structured logs can be converted to agent-ready transitions.
    - K-fold splitting and online replay buffers are not handled here—they belong in `Train`.
    """

    def register_source(self, name: str, data: Iterable) -> None:
        pass

    def load_exclusion_keys(self, tag: str, path: Optional[str] = None) -> None:
        pass

    def set_split(self, train: float, val: float = 0.0, test: float = 0.0, seed: Optional[int] = None) -> None:
        pass

    def apply_rolling_windows(self, window_size: int, step: int = 1) -> None:
        pass

    def convert(self, output_format: str = "npy", output_dir: str = "./data/processed/") -> None:
        pass

    def prepare_rl_dataset(
        self,
        state_source: Iterable,
        action_source: Iterable,
        reward_source: Iterable,
        next_state_source: Iterable,
        done_source: Iterable,
        output_format: str = "npy",
        output_dir: str = "./data/rl/"
    ) -> None:
        pass

    def save_metadata(self, path: str = "./data/processed/metadata.json") -> None:
        pass    
